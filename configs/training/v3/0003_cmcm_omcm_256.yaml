image_finetune: false

output_dir: "/group/40034/zhouxiawang/outputs/motionctrl_animatediff/experiments"
pretrained_model_path: "models/StableDiffusion/stable-diffusion-v1-5"

unet_additional_kwargs:
  use_inflated_groupnorm:     true # v2: without this line
  use_motion_module:          true
  motion_module_resolutions:  [1,2,4,8]
  motion_module_mid_block:    false # v2: true
  motion_module_type:         Vanilla

  motion_module_kwargs:
    num_attention_heads:                 8
    num_transformer_block:               1
    attention_block_types:               [ "Temporal_Self", "Temporal_Self" ]
    temporal_position_encoding:          true
    temporal_position_encoding_max_len:  32
    temporal_attention_dim_div:          1
    zero_initialize:                     true


noise_scheduler_kwargs:
  num_train_timesteps: 1000
  beta_start:          0.00085
  beta_end:            0.012
  beta_schedule:       "linear"
  steps_offset:        1
  clip_sample:         false

train_data:
  target: motionctrl.data.webvid_motion_trajectory_anyspatio.WebVid
  params:
        data_dir: /group/40033/public_datasets/WebVid
        meta_path: /group/40033/public_datasets/WebVid/meta_data/results_2M_train.csv
        motion_seg_list: /group/40033/public_datasets/WebVid/motion_seg_list_v2.txt
        video_length: 16
        frame_stride:
        - 1
        - 2
        trajectory_type: dense
        spatial_transform: align2_256
        resolution: [256,256]
        load_raw_resolution: True
  sample_size: 256
  sample_n_frames: 16

validation_data:
  prompts:
    - "a sunflower swaying in the wind."
    - "a man surfing."

  traj_paths:
    - /group/30098/zhouxiawang/project/MotionCtrlV2/examples/trajectories/shaking_10.npy
    - /group/30098/zhouxiawang/project/MotionCtrlV2/examples/trajectories/curve_2.npy
  
  num_inference_steps: 25
  guidance_scale: 8.

trainable_modules: ~
  # - "motion_modules."

# unet_checkpoint_path: "models/Motion_Module/mm_sd_v15_v2.ckpt"
# unet_checkpoint_path: "models/Motion_Module/v3_sd15_mm.ckpt"
unet_checkpoint_path: "/group/40034/zhouxiawang/outputs/motionctrl_animatediff/experiments/0001_cmcm_bs2_lr0.0001_ccm4-2024-05-15T18-54-39/checkpoints/checkpoint-epoch-23.ckpt"

learning_rate:    1.e-4
train_batch_size: 1
gradient_accumulation_steps: 4

max_train_epoch:      -1
max_train_steps:      1000000
checkpointing_epochs: -1
checkpointing_steps:  1000

validation_steps:       1000
validation_steps_tuple: [2, 50, 500]

global_seed: 42
mixed_precision_training: true
enable_xformers_memory_efficient_attention: True

is_debug: false

# cmcm
enable_cmcm: False

# omcm
enable_omcm: true
omcm_min_step: 700
min_step_prob: 0.8

omcm_config: 
  pretrained: ~
  params:
    channels:
      - 320
      - 640
      - 1280
      - 1280
    nums_rb: 2
    cin: 128 # 2 * 8 * 8
    sk: True
    use_conv: False